# xhs_crawler.py 开发问题与解决方案总结

本文档总结了在将 MediaCrawler 项目重构为单文件爬虫 `xhs_crawler.py` 过程中遇到的主要问题及其解决方案。

## 1. 依赖库导致的程序崩溃

**问题描述：**
原项目依赖 `cv2` (OpenCV)、`matplotlib` 和 `wordcloud` 等库。在用户的运行环境中，这些库导致了严重的程序崩溃（如 Python 进程直接退出），且对于仅抓取图文对的爬虫来说，这些是严重的非必要依赖。

**解决方案：**
- **移除依赖：** 在 `tools/utils.py`、`tools/words.py` 和 `tools/async_file_writer.py` 中，注释掉了所有涉及 `cv2`、`matplotlib` 和 `wordcloud` 的引用和代码块。
- **精简逻辑：** 确保爬虫核心只依赖 `playwright`、`httpx` 等必要库，显著提高了程序的稳定性和启动速度。

## 2. 登录过程中的超时问题

**问题描述：**
使用 `page.wait_for_navigation()` 或 `page.wait_for_url()` 等待登录完成时，由于网络波动或页面加载行为的不确定性，经常出现超时错误。

**解决方案：**
- **优化等待策略：** 将 `wait_until` 参数设置为 `"domcontentloaded"`，不再等待所有资源（如图片）加载完毕。
- **元素检测：** 改为检测登录后才会出现的特定元素（如搜索框或头像），这种方式比等待页面跳转事件更加可靠。

## 3. 反爬虫 461 错误 (Forbidden/Anti-Spider)

**问题描述：**
在成功登录并获取搜索结果后，尝试调用 `/api/sns/web/v1/feed` 接口获取笔记详情时，服务器频繁返回 `461` 状态码。这是小红书的一种风控机制，表明请求被识别为机器人。

**解决方案：**
- **模拟真实流量（初期尝试）：** 尝试在调用 API 前控制浏览器跳转到笔记详情页，希望借此通过风控检测，但效果不佳且效率极低。
- **完善 API 签名与 Payload：** 这是解决问题的关键。通过分析原仓库代码，发现之前的 API 请求体（Payload）缺少关键参数。
    - **修正 Payload：** 补充了 `source_note_id`, `image_formats`, `extra`, `xsec_source` 等字段，使其与官方客户端行为完全一致。
    - **集成 `xsec_token`：** 实现了从搜索 API 响应中提取 `xsec_token`，并将其正确传递给详情 API。

## 4. `xsec_token` 的获取与传递

**问题描述：**
用户指出详情页 API 的调用需要 `xsec_token`，且该 Token 包含在搜索结果中。早期的代码试图通过模拟 UI 搜索来抓取数据，难以稳定提取该 Token。

**解决方案：**
- **API 优先策略：** 放弃 UI 模拟搜索，改为直接调用搜索接口 `/api/sns/web/v1/search/notes`。
- **数据提取：** 该接口直接返回 JSON 数据，其中包含了每一篇笔记的 `xsec_token`。程序直接解析 JSON 即可获取，无需从复杂的 DOM 结构中提取。

## 5. 笔记 ID 格式错误导致 "笔记不存在"

**问题描述：**
从搜索结果中提取的某些 `note_id` 带有后缀（如 `#timestamp`），直接使用这些 ID 请求详情 API 会导致 API 返回“笔记不存在”的错误。

**解决方案：**
- **数据清洗：** 在获取 `note_id` 后增加预处理逻辑，检测并移除 `#` 及其之后的所有字符，确保 ID 格式纯净。

## 6. 搜索结果混杂非笔记内容

**问题描述：**
搜索 API 返回的结果中包含用户、视频、合集等多种类型的内容。爬虫尝试对所有内容调用笔记详情接口，导致报错。

**解决方案：**
- **类型过滤：** 在遍历搜索结果时，增加 `if item.get("model_type") != "note": continue` 判断，仅处理图文笔记类型的数据。

## 7. 爬取效率低下

**问题描述：**
为了规避 461 错误，曾尝试每抓取一篇笔记就控制浏览器打开一个新的标签页跳转到详情页。这导致爬虫运行极慢，大量时间消耗在页面渲染上。

**解决方案：**
- **移除页面跳转：** 在解决了 API Payload 和 `xsec_token` 的问题后，API 调用已经足够“真实”且能通过验证。因此移除了所有不必要的 `page.goto` 操作，实现了纯 API 级别的数据抓取，效率提升数倍。

## 8. 代码语法与调用错误

**问题描述：**
在快速迭代过程中，引入了 `IndentationError`（缩进错误）和 `TypeError`（函数参数错误，如给 `sign_with_playwright` 传递了多余的 `method` 参数）。

**解决方案：**
- **代码审查与修正：** 及时修正了缩进问题，并清理了函数调用中不匹配的参数，确保代码符合 Python 语法规范且逻辑正确。
