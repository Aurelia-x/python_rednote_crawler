# 小红书自动发布器设计思路

## 1. 项目简介

本项目是小红书自动化生态的“输出端”，旨在通过自动化手段将本地准备好的素材（图片、标题、正文）发布到小红书网页版。它模拟了真实用户的发帖行为，解放了重复性的手动上传工作，并集成了 AI 文案生成功能，实现了从“素材”到“成品笔记”的一键转化。

## 2. 核心原理：纯浏览器自动化 + AI 赋能

与爬虫（输入端）采用的“混合模式”不同，发布器（输出端）采用的是 **"纯浏览器自动化（Playwright）"** 策略。

*   **为什么不用 API？**：发布接口涉及复杂的各种校验（包括且不限于图片上传的加密参数、行为轨迹验证、风控指纹等），逆向 API 的成本极高且极不稳定。
*   **回归本质**：发布操作频率相对较低（每天几条），对速度要求不高，但对**成功率**和**安全性**要求极高。模拟真人操作浏览器是最稳妥的方案。
*   **AI 赋能**：在发布前，引入了阿里云 Qwen-VL 多模态大模型，它能“看懂”你要发的图片，自动创作出符合小红书风格的爆款文案，解决了“不知道写什么”的痛点。

## 3. 核心难点与解决方案

### 3.1 难点一：复杂的 UI 交互流程
小红书发布页面是一个高度动态的单页应用（SPA）。
*   **默认上传视频**：进入页面默认是视频上传，需要精准切换到“图文”模式。
*   **非标准输入框**：正文编辑区不是标准的 `<input>` 或 `<textarea>`，而是一个 `contenteditable` 的 `div`，普通的 `fill` 方法有时会失效。
*   **弹窗干扰**：浏览器可能会弹出“获取地理位置”的权限请求，打断自动化流程。

**解决方案**：
*   **精准定位**：利用 Playwright 的 `get_by_text` 和 `hover` 组合操作，模拟鼠标悬停唤出菜单，精准点击“上传图文”。
*   **强力注入**：针对 `contenteditable` 元素，先 `click` 聚焦，再使用 Playwright 对富文本编辑器的专门支持进行输入。
*   **脚本屏蔽**：在浏览器启动时注入 JavaScript 代码，重写 `navigator.geolocation`，自动拒绝所有地理位置请求，把弹窗扼杀在摇篮里。

### 3.2 难点二：文件上传
网页上的文件上传通常需要弹出一个操作系统的文件选择框，自动化脚本无法控制操作系统的窗口。

**解决方案**：
*   **`set_input_files`**：Playwright 提供了一个强大的 API。我们不需要真的去点“上传”按钮，而是直接找到页面背后隐藏的 `<input type="file">` 标签，直接把本地文件路径“塞”进去。这不仅绕过了操作系统弹窗，还支持一次性上传多张图片。

### 3.3 难点三：账号登录状态维持
每次发布都重新扫码登录是不现实的。

**解决方案**：
*   **Cookie 移植**：复用爬虫阶段获取的 `cookies.json`。在启动浏览器上下文时，直接注入这些 Cookie。
*   **双重检查**：在操作前，先访问主页并检查“搜索框”是否存在。如果 Cookie 过期，程序会立即报错并停止，避免做无用功。

## 4. 程序逻辑流程（技术架构视图）

我们将发布流程划分为三个阶段：**数据准备**、**环境初始化**、**自动化执行**。

### 4.1 第一阶段：数据准备 (Data Preparation)
1.  **素材加载**：根据 `note_id` 扫描本地目录下的图片文件，读取 `annotations.json` 中的元数据。
2.  **AI 文案生成 (Optional)**：
    *   调用 `generate_ai_copywriting` 函数。
    *   将图片转为 Base64 编码，连同原始标题发送给 Qwen-VL 大模型。
    *   模型返回优化后的标题和正文（JSON 格式）。

### 4.2 第二阶段：环境初始化 (Initialization)
1.  **启动浏览器**：`playwright.chromium.launch(headless=False)`。这里必须用**有头模式**，因为发布操作涉及大量复杂的渲染和反爬检测，无头模式容易被风控识别。
2.  **反自动化特征**：注入 `navigator.webdriver` 隐藏脚本。
3.  **权限屏蔽**：注入 Geolocation 屏蔽脚本。
4.  **身份注入**：读取并加载 Cookies。

### 4.3 第三阶段：自动化执行 (Execution)
1.  **导航与模式切换**：
    *   点击“发布” -> 悬停“发布笔记” -> 点击“上传图文”。
2.  **图片上传**：
    *   定位 `input[type='file']` -> `setInputFiles(images)`。
    *   **关键等待**：必须等待图片预览元素（`.preview-item`）出现，确保图片已上传至服务器。
3.  **内容填充**：
    *   填标题 -> 填正文 -> 勾选“内容来源声明”（防止限流）。
4.  **最终提交**：
    *   点击“发布”按钮。
    *   等待“发布成功”提示。

## 5. 代码模块说明

*   **`xhs_publisher.py`**：
    *   **`XhsPublisher` 类**：
        *   `start()`: 负责浏览器的生与死，以及 Cookie 的注入。
        *   `publish_note()`: 执行具体的 UI 操作逻辑，是全程序最复杂的部分。
        *   `check_login()`: 守门员，确保身份有效。
    *   **`generate_ai_copywriting` 函数**：独立的 AI 模块，负责与阿里云 DashScope API 通信。

## 6. 零基础入门：发布器是如何工作的？

如果说爬虫是“把餐厅的菜单抄回家”，那么发布器就是**“派机器人去餐厅后厨贴海报”**。

### 6.1 核心流程图解（贴海报比喻）

#### 第一步：穿上制服（身份伪装）
*   **代码**：`add_cookies`
*   **解释**：机器人（浏览器）穿上了餐厅员工的制服（加载 Cookie），这样进出后厨（创作中心）才不会被保安拦住。同时，它还戴上了墨镜（屏蔽地理位置），不让别人看出它是哪里来的。

#### 第二步：准备海报（AI 创作）
*   **代码**：`generate_ai_copywriting`
*   **解释**：你给了机器人几张原材料图片。机器人先找了一位艺术大师（AI 大模型），问：“大师，这几张图怎么配文案才火？”大师大笔一挥，写好了标题和正文。

#### 第三步：张贴海报（自动化操作）
这是最精彩的**“无实物表演”**：
1.  **进门**：机器人点击“发布”按钮，走进创作中心。
2.  **选墙面**：本来墙上默认是挂电视的（上传视频），机器人熟练地按了一个开关，把墙面变成了贴画模式（上传图文）。
3.  **贴图**：机器人不需要一张张涂胶水。它直接用魔法（`set_input_files`）把手里的一叠照片瞬间印到了墙上。
4.  **写字**：机器人拿起笔，在标题栏和正文栏飞快地抄写大师给的文案。
5.  **盖章**：并在角落里盖上“原创声明”的印章。
6.  **完工**：最后用力拍下“发布”按钮。搞定！

### 6.2 为什么有时候会看到浏览器自己动？
这就是我们在代码里设置 `headless=False` 的原因。
*   一方面是为了**骗过小红书**，让它以为是真人在操作（有头浏览器的环境特征更真实）。
*   另一方面是为了**让你看见**。看着机器人一步步帮你干活，是不是很有成就感？

### 6.3 什么是“干跑模式”（Dry Run）？
在代码里有一个 `dry_run` 参数。
*   如果开启了这个模式，机器人会做完贴图、写字等所有动作，但**最后一步绝不按“发布”按钮**。
*   这就像是**彩排**。你可以检查一下图片对不对、文案好不好。确认无误后，再关掉彩排模式，让它真发。
